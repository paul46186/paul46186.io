{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0634da95",
   "metadata": {},
   "source": [
    "### CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e90d8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import docx2txt\n",
    "import textract\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def read_pdf_resume(fileName):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    with open(fileName, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, caching=True,check_extractable=True):           \n",
    "            page_interpreter.process_page(page)     \n",
    "        text = fake_file_handle.getvalue() \n",
    "    # close open handles      \n",
    "    converter.close() \n",
    "    fake_file_handle.close() \n",
    "    return text\n",
    "        \n",
    "def clean_text(text): ## Clean the Text\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    clean_text = text.lower()\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "    clean_text = clean_text.strip()\n",
    "    clean_text = re.sub('[0-9]+', '', clean_text)\n",
    "    clean_text = word_tokenize(clean_text)\n",
    "    #stop = stopwords.words('english')\n",
    "    clean_text = [lemmatizer.lemmatize(token) for token in clean_text if token.isalnum()] \n",
    "    clean=' '.join(clean_text)\n",
    "    return(clean)\n",
    "\n",
    "def get_resume_score(text):\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    #Print the similarity scores\n",
    "    print(\"\\nSimilarity Scores:\")\n",
    "    #get the match percentage\n",
    "    matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "    matchPercentage = round(matchPercentage, 2) # round to two decimal\n",
    "    print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description.\")\n",
    "\n",
    "def read_word_resume(fileName):\n",
    "    resume = docx2txt.process(fileName)\n",
    "    resume = str(resume)\n",
    "    text =  ''.join(resume)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    return resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17180a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your file format? please input word or pdf pdf\n",
      "pdf\n",
      "Enter your file name Kaiduan Chang Resume.pdf\n",
      "\n",
      "Enter the Job Description: Job Description  The Technology Planning & Business Operations (TPBO) organization provides key strategic planning & business operations oversight and integration across the Technology organization. This includes driving investment planning & budgeting, project & portfolio management, strategic initiative program management, and communications activities. The team is focused on improving efficiencies, transparency, consistency and collaboration within the Technology organization and other key cross-functional stakeholders.  Job Purpose  The Associate Analyst will be responsible for supporting several Technology Planning & Business Operations activities. This includes supporting program management of strategic initiatives, Technology procurement pipeline & supplier deal coordination, and driving ad-hoc business management analysis. This position interacts with many cross-functional stakeholders, including various Technology teams, Finance, Sourcing, and other functions. This position will report to the Sr. Director of Technology Strategic Initiatives.  Responsibilities Support program management and business analysis for various strategic Technology initiatives, owning various components of the initiatives Develop detailed financial models and business updates to drive the proactive management of strategic programs and procurement activities Support the automation of business processes & systems related to Technology supplier utilization and procurement pipeline Provide ad hoc support for other business management activities as needed QualificationsBasic Qualifications Minimum of 6 months of work experience or a Bachelor's Degree Bachelor’s degree in Finance, Business Administration, Economics, or a related field Solid analytical and problem-solving skills; prior financial budget and modeling experience preferred Proficiency in the use of Microsoft Office tools (specifically Word and Excel, Access is a plus) Strong verbal and written communication skills, attention to detail and interpersonal skills Ability to work independently with strong time management and ability to execute on multiple concurrent deliverables Educational or prior project management job experience a plus Prior experience working with reporting & data visualization systems such as SQL, Access, Tableau,\n",
      "\n",
      "Similarity Scores:\n",
      "Your resume matches about 18.96% of the job description.\n"
     ]
    }
   ],
   "source": [
    "Resume_file=input('What is your file format? please input word or pdf ').lower()\n",
    "print(Resume_file)\n",
    "file=['pdf','word','1']\n",
    "\n",
    "while Resume_file not in file:\n",
    "    print(\"Invaild!\")\n",
    "    Resume_file=input(\"Please input a correct file format or 1 or exit: \").lower()\n",
    "if  Resume_file=='1':\n",
    "    print('Ok bye!')\n",
    "    \n",
    "elif Resume_file == 'pdf':\n",
    "    fileName=input('Enter your file name ')\n",
    "    job_description = input(\"\\nEnter the Job Description: \") \n",
    "    clean_resume = clean_text(read_pdf_resume(fileName)) \n",
    "    clean_job_description = clean_text(job_description) \n",
    "    clean_format = [clean_resume, clean_job_description] \n",
    "    ## Get a Match score\n",
    "    get_resume_score(clean_format)\n",
    "    \n",
    "else:    \n",
    "    fileName=input('Enter your file name ')\n",
    "    job_description = input(\"\\nEnter the Job Description: \") \n",
    "    clean_resume = clean_text(read_word_resume(fileName)) \n",
    "    clean_job_description = clean_text(job_description) \n",
    "    clean_format = [clean_resume, clean_job_description]\n",
    "    ## Get a Match score\n",
    "    get_resume_score(clean_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183ddda",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88528257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import docx2txt\n",
    "import textract\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def read_pdf_resume(fileName):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    with open(fileName, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, caching=True,check_extractable=True):           \n",
    "            page_interpreter.process_page(page)     \n",
    "        text = fake_file_handle.getvalue() \n",
    "    # close open handles      \n",
    "    converter.close() \n",
    "    fake_file_handle.close() \n",
    "    return text\n",
    "\n",
    "def read_word_resume(fileName):\n",
    "    resume = docx2txt.process(fileName)\n",
    "    resume = str(resume)\n",
    "    text =  ''.join(resume)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    return resume\n",
    "\n",
    "def clean_text(text): ## Clean the Text\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    clean_text = text.lower()\n",
    "     # remove punctuation\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "     # remove trailing spaces\n",
    "    clean_text = clean_text.strip()\n",
    "     # remove numbers\n",
    "    clean_text = re.sub('[0-9]+', '', clean_text)\n",
    "     # tokenize \n",
    "    clean_text = word_tokenize(clean_text)\n",
    "     # remove stop words\n",
    "    clean_text = [lemmatizer.lemmatize(token) for token in clean_text if token.isalnum()] \n",
    "    clean=' '.join(clean_text)\n",
    "    return(clean)\n",
    "\n",
    "def get_resume_score(text):\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (1,2),min_df=2)\n",
    "    count_matrix=vectorizer.fit_transform(text)\n",
    "    #Print the similarity scores\n",
    "    print(\"\\nSimilarity Scores:\")\n",
    "    #get the match percentage\n",
    "    matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "    matchPercentage = round(matchPercentage, 2) # round to two decimal\n",
    "    print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45cb4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your file format? please input word or pdf pdf\n",
      "pdf\n",
      "Enter your file name: Kaiduan Chang Resume.pdf\n",
      "\n",
      "Enter the Job Description: Responsibilities  • Work with email, creative, and media buying teams to analyze campaigns and make testing recommendations based on past performance  • Advocate for A/B and multivariate tests based on performance data, email best practices, insights from across the business and competitive analysis  • Test campaigns, analyzing key metrics, and identifying opportunities to increase campaign performance  • Conduct analysis that results in actionable insights and data-driven recommendations  • Create dashboards, data visualizations, and campaign performance reports  • Automate reports as much as possible and look for ways to evolve how we measure success   Skills and Personal Attributes  ▪️ Extremely analytical with demonstrated ability to use data to problem-solve and optimize outcomes  ▪️ Self-starter who can power through challenges and thrives in a fast-paced, dynamic start-up environment.  ▪️ Excellent attention to detail and project management skills  ▪️ Superb work ethic and positive, can-do attitude  ▪️ High levels of organisation, with strong planning skills and the ability to prioritise a large workload according to ever changing business needs  ▪️ Able to communicate and work cross-functionally\n",
      "\n",
      "Similarity Scores:\n",
      "Your resume matches about 86.04% of the job description.\n"
     ]
    }
   ],
   "source": [
    "Resume_file=input('What is your file format? please input word or pdf ').lower()\n",
    "print(Resume_file)\n",
    "file=['pdf','word','1']\n",
    "\n",
    "while Resume_file not in file:\n",
    "    print(\"Invaild!\")\n",
    "    Resume_file=input(\"Please input a correct file format or 1 or exit: \").lower()\n",
    "\n",
    "if  Resume_file=='1':\n",
    "    print('Ok bye!')\n",
    "    \n",
    "elif Resume_file == 'pdf':\n",
    "    fileName=input('Enter your file name: ')\n",
    "    job_description = input(\"\\nEnter the Job Description: \") \n",
    "    clean_resume = clean_text(read_pdf_resume(fileName)) \n",
    "    clean_job_description = clean_text(job_description) \n",
    "    clean_format = [clean_resume, clean_job_description] \n",
    "    ## Get a Match score\n",
    "    get_resume_score(clean_format)\n",
    "else:    \n",
    "    fileName=input('Enter your file name: ')\n",
    "    job_description = input(\"\\nEnter the Job Description: \") \n",
    "    clean_resume = clean_text(read_word_resume(fileName)) \n",
    "    clean_job_description = clean_text(job_description) \n",
    "    clean_format = [clean_resume, clean_job_description]\n",
    "    ## Get a Match score\n",
    "    get_resume_score(clean_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e62096",
   "metadata": {},
   "source": [
    "### Euclidean Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ae134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import docx2txt\n",
    "import textract\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def read_pdf_resume(fileName):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    with open(fileName, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, caching=True,check_extractable=True):           \n",
    "            page_interpreter.process_page(page)     \n",
    "        text = fake_file_handle.getvalue() \n",
    "    # close open handles      \n",
    "    converter.close() \n",
    "    fake_file_handle.close() \n",
    "    return text\n",
    "        \n",
    "def clean_text(text): ## Clean the Text\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    clean_text = text.lower()\n",
    "     # remove punctuation\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "     # remove trailing spaces\n",
    "    clean_text = clean_text.strip()\n",
    "     # remove numbers\n",
    "    clean_text = re.sub('[0-9]+', '', clean_text)\n",
    "     # tokenize \n",
    "    clean_text = word_tokenize(clean_text)\n",
    "     # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    clean_text = [lemmatizer.lemmatize(token) for token in clean_text if not token in stop if token.isalnum()] \n",
    "    clean=' '.join(clean_text)\n",
    "    return(clean)\n",
    "\n",
    "def get_resume_score(text):\n",
    "    cv = TfidfVectorizer()\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    #Print the similarity scores\n",
    "    print(\"\\nSimilarity Scores:\")\n",
    "    #get the match percentage\n",
    "    Score = euclidean_distances(count_matrix)[0][1]\n",
    "    Score = round(Score, 2) # round to two decimal\n",
    "    print(\"Your resume got \"+ str(Score)+ \" with euclidean_distances. The smaller the better.\")\n",
    "\n",
    "def read_word_resume(fileName):\n",
    "    resume = docx2txt.process(fileName)\n",
    "    resume = str(resume)\n",
    "    text =  ''.join(resume)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    return resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resume_file=input('What is your file format? please input word or pdf ').lower()\n",
    "print(Resume_file)\n",
    "file=['pdf','word','1']\n",
    "\n",
    "while Resume_file not in file:\n",
    "    print(\"Invaild!\")\n",
    "    Resume_file=input(\"Please input a correct file format or 1 or exit: \").lower()\n",
    "if  Resume_file=='1':\n",
    "    print('Ok bye!')\n",
    "elif Resume_file == 'pdf':\n",
    "    fileName=input('Enter your file name ')\n",
    "    \n",
    "    job_description = input(\"\\nEnter the Job Description: \") \n",
    "    clean_resume = clean_text(read_pdf_resume(fileName)) \n",
    "    clean_job_description = clean_text(job_description) \n",
    "    clean_format = [clean_resume, clean_job_description] \n",
    "    ## Get a Match score\n",
    "    get_resume_score(clean_format)\n",
    "else:    \n",
    "    fileName=input('Enter your file name ')\n",
    "    \n",
    "    job_description = input(\"\\nEnter the Job Description: \") \n",
    "    clean_resume = clean_text(read_word_resume(fileName)) \n",
    "    clean_job_description = clean_text(job_description) \n",
    "    clean_format = [clean_resume, clean_job_description]\n",
    "    ## Get a Match score\n",
    "    get_resume_score(clean_format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
